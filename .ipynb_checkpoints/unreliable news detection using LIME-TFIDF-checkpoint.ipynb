{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eba7c71",
   "metadata": {},
   "source": [
    "### Optimizing Rumor Detection: A Dual Feature Extraction Approach with LIME-Based Model Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1eb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "# from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3455551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset link = https://www.kaggle.com/c/fake-news/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9198a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627542b5",
   "metadata": {},
   "source": [
    "1 ==> unreliable / rumor\n",
    "\n",
    "0 ==> reliable / non-rumor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a274160a",
   "metadata": {},
   "source": [
    "Balanced Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'author', 'title'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadca767",
   "metadata": {},
   "source": [
    "### Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7be089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf34a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The forwardfill() method is used to fill in missing values \n",
    "# in a DataFrame or Series with the previous valid observation\n",
    "\n",
    "df['text'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4546f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be98a9",
   "metadata": {},
   "source": [
    "### Duplicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c65aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping Duplicates\n",
    "\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7454b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1884f8b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe100b",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have the necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Constants for cleaning\n",
    "PUNCT_TO_REMOVE = string.punctuation + '“”'\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordnet_map = {\"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"J\": wordnet.ADJ, \"R\": wordnet.ADV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all cleaning functions\n",
    "def clean_text(text, FREQWORDS=None, RAREWORDS=None):\n",
    "    if isinstance(text, str):\n",
    "        # 1. Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # 2. Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "        \n",
    "        # 3. Remove hyperlinks, markup, numbers, and special symbols\n",
    "        text = re.sub(\"<[a][^>]*>(.+?)</[a]>\", 'Link.', text)\n",
    "        text = re.sub('&gt;', \"\", text)  # Greater than sign\n",
    "        text = re.sub('&#x27;', \"'\", text)  # Apostrophe\n",
    "        text = re.sub('&quot;', '\"', text)\n",
    "        text = re.sub('&#x2F;', ' ', text)\n",
    "        text = re.sub('<p>', ' ', text)  # Paragraph tag\n",
    "        text = re.sub('<i>', ' ', text)  # Italics tag\n",
    "        text = re.sub('</i>', '', text)\n",
    "        text = re.sub('&#62;', '', text)\n",
    "        text = re.sub(\"\\n\", '', text)  # Newline\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "        text = re.sub(r\"[’']\", \"\", text)  # Remove special apostrophes\n",
    "\n",
    "        # 4. Remove stopwords\n",
    "        text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "        \n",
    "        # 5. Remove frequent words if provided\n",
    "        if FREQWORDS:\n",
    "            text = \" \".join([word for word in text.split() if word not in FREQWORDS])\n",
    "        \n",
    "        # 6. Remove rare words if provided\n",
    "        if RAREWORDS:\n",
    "            text = \" \".join([word for word in text.split() if word not in RAREWORDS])\n",
    "        \n",
    "        # 7. Lemmatization\n",
    "        pos_tagged_text = nltk.pos_tag(text.split())\n",
    "        text = \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "        \n",
    "        # 8. Remove URLs\n",
    "        url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        text = url_pattern.sub(r'', text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function on the dataset\n",
    "def preprocess_df(df):\n",
    "    # Remove URLs, Punctuation, Lowercase, etc. in one go\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda text: clean_text(text))\n",
    "\n",
    "    # Get frequent words and remove them\n",
    "    cnt = Counter()\n",
    "    for text in df[\"text\"].values:\n",
    "        for word in text.split():\n",
    "            cnt[word] += 1\n",
    "    FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "    \n",
    "    # Get rare words and remove them\n",
    "    rare_word_count = pd.Series(' '.join(df['text']).split()).value_counts()[-2:]\n",
    "    RAREWORDS = list(rare_word_count.index)\n",
    "    \n",
    "    # Apply removal of frequent and rare words\n",
    "    df[\"text\"] = df[\"text\"].apply(lambda text: clean_text(text, FREQWORDS=FREQWORDS, RAREWORDS=RAREWORDS))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function to clean and preprocess the dataframe\n",
    "df = preprocess_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba5165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e054ecd",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']  # Features\n",
    "y = df['label'] # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0566645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a830aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534f37a",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Custom parameters for CountVectorizer\n",
    "# count_vect = CountVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "\n",
    "# Custom parameters for TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CountVectorizer\n",
    "# X_count = count_vect.fit_transform(X)\n",
    "\n",
    "\n",
    "# Apply TfidfVectorizer\n",
    "X_tfidf = tfidf_vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of correct data splitting\n",
    "# X_train_count, X_test_count, y_train, y_test = train_test_split(X_count, y, test_size=0.2, random_state=42)\n",
    "# X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ad445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"X_train_count shape: {X_train_count.shape}\")\n",
    "# print(f\"y_train shape: {y_train.shape}\")\n",
    "# print(f\"X_test_count shape: {X_test_count.shape}\")\n",
    "# print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# print(f\"X_train_tfidf shape: {X_train_tfidf.shape}\")\n",
    "# print(f\"y_train shape: {y_train.shape}\")\n",
    "# print(f\"X_test_tfidf shape: {X_test_tfidf.shape}\")\n",
    "# print(f\"y_train shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821477e",
   "metadata": {},
   "source": [
    "## Model Training - TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487f03c",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression model\n",
    "log_reg_tf = LogisticRegression(max_iter=1000, solver='lbfgs', C=1.0, penalty='l2')\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "# Initialize metrics to accumulate results\n",
    "conf_matrix_sum = np.zeros((2, 2))  # for binary classification (2x2 confusion matrix)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation manually\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_tfidf, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold using .iloc for positional indexing\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use iloc to select by position\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    log_reg_tf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = log_reg_tf.predict(X_test)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_sum += conf_matrix  # Accumulate the confusion matrices\n",
    "    \n",
    "     # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print the final averaged metrics\n",
    "print(\"\\n=== Final Averaged Metrics Across All Folds ===\")\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f}')\n",
    "print(f'Mean F1 Score: {np.mean(f1_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f}')\n",
    "\n",
    "# Print the final summed confusion matrix\n",
    "print(\"\\n=== Final Summed Confusion Matrix Across All Folds ===\")\n",
    "print(conf_matrix_sum.astype(int))  # Convert to integer for cleaner display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Logistic Regression with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "# joblib.dump(log_reg_tf, 'logistic_regression_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8752ace",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cedd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes model\n",
    "naive_bayes_tf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "# Initialize metrics to accumulate results\n",
    "conf_matrix_sum = np.zeros((2, 2))  # for binary classification (2x2 confusion matrix)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation manually\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_tfidf, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold using .iloc for positional indexing\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use iloc to select by position\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    naive_bayes_tf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = naive_bayes_tf.predict(X_test)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_sum += conf_matrix  # Accumulate the confusion matrices\n",
    "    \n",
    "     # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print the final averaged metrics\n",
    "print(\"\\n=== Final Averaged Metrics Across All Folds ===\")\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f}')\n",
    "print(f'Mean F1 Score: {np.mean(f1_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f}')\n",
    "\n",
    "# Print the final summed confusion matrix\n",
    "print(\"\\n=== Final Summed Confusion Matrix Across All Folds ===\")\n",
    "print(conf_matrix_sum.astype(int))  # Convert to integer for cleaner display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Naive Bayes with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321eede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "# joblib.dump(naive_bayes_tf, 'naive_bayes_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c6b97",
   "metadata": {},
   "source": [
    "### 3. Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d62eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Stochastic Gradient Descent (SGD) Classifier\n",
    "sgd_tf = SGDClassifier(loss='hinge', penalty='l2', max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "# Initialize metrics to accumulate results\n",
    "conf_matrix_sum = np.zeros((2, 2))  # for binary classification (2x2 confusion matrix)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation manually\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_tfidf, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold using .iloc for positional indexing\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use iloc to select by position\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    sgd_tf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = sgd_tf.predict(X_test)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_sum += conf_matrix  # Accumulate the confusion matrices\n",
    "    \n",
    "     # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print the final averaged metrics\n",
    "print(\"\\n=== Final Averaged Metrics Across All Folds ===\")\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f}')\n",
    "print(f'Mean F1 Score: {np.mean(f1_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f}')\n",
    "\n",
    "# Print the final summed confusion matrix\n",
    "print(\"\\n=== Final Summed Confusion Matrix Across All Folds ===\")\n",
    "print(conf_matrix_sum.astype(int))  # Convert to integer for cleaner display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c13d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - SGD Classifier with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d59166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "joblib.dump(sgd_tf, 'stochastic_gradient_descent_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b16028",
   "metadata": {},
   "source": [
    "### 4. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN model\n",
    "knn_tf = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # p=2 means Euclidean distance\n",
    "\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "# Initialize metrics to accumulate results\n",
    "conf_matrix_sum = np.zeros((2, 2))  # for binary classification (2x2 confusion matrix)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation manually\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_tfidf, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold using .iloc for positional indexing\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use iloc to select by position\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    knn_tf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn_tf.predict(X_test)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_sum += conf_matrix  # Accumulate the confusion matrices\n",
    "    \n",
    "     # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print the final averaged metrics\n",
    "print(\"\\n=== Final Averaged Metrics Across All Folds ===\")\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f}')\n",
    "print(f'Mean F1 Score: {np.mean(f1_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f}')\n",
    "\n",
    "# Print the final summed confusion matrix\n",
    "print(\"\\n=== Final Summed Confusion Matrix Across All Folds ===\")\n",
    "print(conf_matrix_sum.astype(int))  # Convert to integer for cleaner display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - K-Nearest Neighbors with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "# joblib.dump(knn_tf, 'k-nearest_neighbors_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d480c4",
   "metadata": {},
   "source": [
    "### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce68ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Decision Tree model\n",
    "decision_tree_tf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, random_state=42)\n",
    "\n",
    "# Define the k-fold cross-validation# Initialize the KNN model\n",
    "knn_tf = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # p=2 means Euclidean distance\n",
    "\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "# Initialize metrics to accumulate results\n",
    "conf_matrix_sum = np.zeros((2, 2))  # for binary classification (2x2 confusion matrix)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation manually\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_tfidf, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold using .iloc for positional indexing\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use iloc to select by position\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    decision_tree_tf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = decision_tree_tf.predict(X_test)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_sum += conf_matrix  # Accumulate the confusion matrices\n",
    "    \n",
    "     # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print the final averaged metrics\n",
    "print(\"\\n=== Final Averaged Metrics Across All Folds ===\")\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f}')\n",
    "print(f'Mean F1 Score: {np.mean(f1_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f}')\n",
    "\n",
    "# Print the final summed confusion matrix\n",
    "print(\"\\n=== Final Summed Confusion Matrix Across All Folds ===\")\n",
    "print(conf_matrix_sum.astype(int))  # Convert to integer for cleaner display\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(decision_tree_tf, X_train_tfidf, y_train, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "# Train the model on the TF-IDF features\n",
    "decision_tree_tf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tfidf_dt = decision_tree_tf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy_tfidf_dt = accuracy_score(y_test, y_pred_tfidf_dt)\n",
    "precision_tfidf_dt = precision_score(y_test, y_pred_tfidf_dt)\n",
    "recall_tfidf_dt = recall_score(y_test, y_pred_tfidf_dt)\n",
    "f1_tfidf_dt = f1_score(y_test, y_pred_tfidf_dt)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Decision Tree with TfidfVectorizer:\")\n",
    "print(f\"Accuracy: {accuracy_tfidf_dt:.4f}\")\n",
    "print(f\"Precision: {precision_tfidf_dt:.4f}\")\n",
    "print(f\"Recall: {recall_tfidf_dt:.4f}\")\n",
    "print(f\"F1 Score: {f1_tfidf_dt:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf_dt))\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix_tfidf_dt = confusion_matrix(y_test, y_pred_tfidf_dt)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix_tfidf_dt, annot=True, fmt='d', cmap='OrRd', xticklabels=['Non-Rumor', 'Rumor'], yticklabels=['Non-Rumor', 'Rumor'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Decision Tree with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Decision Trees with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "joblib.dump(decision_tree_tf, 'decision_tree_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb1481",
   "metadata": {},
   "source": [
    "### 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "random_forest_tf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define the k-fold cross-validation# Initialize the KNN model\n",
    "knn_tf = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # p=2 means Euclidean distance\n",
    "\n",
    "\n",
    "# Initialize k-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits= 5, shuffle=True)\n",
    "\n",
    "# Initialize metrics to accumulate results\n",
    "conf_matrix_sum = np.zeros((2, 2))  # for binary classification (2x2 confusion matrix)\n",
    "\n",
    "# Lists to store metrics for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Perform k-fold cross-validation manually\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_tfidf, y)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Split the data into training and testing sets for this fold using .iloc for positional indexing\n",
    "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Use iloc to select by position\n",
    "    \n",
    "    # Fit the logistic regression model\n",
    "    random_forest_tf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = random_forest_tf.predict(X_test)\n",
    "    \n",
    "    # Update confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix_sum += conf_matrix  # Accumulate the confusion matrices\n",
    "    \n",
    "     # Calculate and store metrics\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    precision_scores.append(precision_score(y_test, y_pred))\n",
    "    recall_scores.append(recall_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print the final averaged metrics\n",
    "print(\"\\n=== Final Averaged Metrics Across All Folds ===\")\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f}')\n",
    "print(f'Mean F1 Score: {np.mean(f1_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f}')\n",
    "\n",
    "# Print the final summed confusion matrix\n",
    "print(\"\\n=== Final Summed Confusion Matrix Across All Folds ===\")\n",
    "print(conf_matrix_sum.astype(int))  # Convert to integer for cleaner display\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(decision_tree_tf, X_train_tfidf, y_train, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "# Train the model on the TF-IDF features\n",
    "decision_tree_tf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tfidf_dt = decision_tree_tf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy_tfidf_dt = accuracy_score(y_test, y_pred_tfidf_dt)\n",
    "precision_tfidf_dt = precision_score(y_test, y_pred_tfidf_dt)\n",
    "recall_tfidf_dt = recall_score(y_test, y_pred_tfidf_dt)\n",
    "f1_tfidf_dt = f1_score(y_test, y_pred_tfidf_dt)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Decision Tree with TfidfVectorizer:\")\n",
    "print(f\"Accuracy: {accuracy_tfidf_dt:.4f}\")\n",
    "print(f\"Precision: {precision_tfidf_dt:.4f}\")\n",
    "print(f\"Recall: {recall_tfidf_dt:.4f}\")\n",
    "print(f\"F1 Score: {f1_tfidf_dt:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf_dt))\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix_tfidf_dt = confusion_matrix(y_test, y_pred_tfidf_dt)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix_tfidf_dt, annot=True, fmt='d', cmap='OrRd', xticklabels=['Non-Rumor', 'Rumor'], yticklabels=['Non-Rumor', 'Rumor'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Decision Tree with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4364c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Random Forest with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "joblib.dump(random_forest_tf, 'random_forest_model_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3d4f3",
   "metadata": {},
   "source": [
    "### 7. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cc73f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ================ without cross validation =================\n",
    "\n",
    "# # Initialize the Support Vector Machine model\n",
    "# svm_tf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# # Train the model on the TF-IDF features\n",
    "# svm_tf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_tfidf_svm = svm_tf.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluation Metrics\n",
    "# accuracy_tfidf_svm = accuracy_score(y_test, y_pred_tfidf_svm)\n",
    "# precision_tfidf_svm = precision_score(y_test, y_pred_tfidf_svm)\n",
    "# recall_tfidf_svm = recall_score(y_test, y_pred_tfidf_svm)\n",
    "# f1_tfidf_svm = f1_score(y_test, y_pred_tfidf_svm)\n",
    "\n",
    "# # Print the evaluation results\n",
    "# print(f\"Support Vector Machine with TfidfVectorizer:\")\n",
    "# print(f\"Accuracy: {accuracy_tfidf_svm:.4f}\")\n",
    "# print(f\"Precision: {precision_tfidf_svm:.4f}\")\n",
    "# print(f\"Recall: {recall_tfidf_svm:.4f}\")\n",
    "# print(f\"F1 Score: {f1_tfidf_svm:.4f}\")\n",
    "\n",
    "# # Print classification report\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred_tfidf_svm))\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# conf_matrix_tfidf_svm = confusion_matrix(y_test, y_pred_tfidf_svm)\n",
    "# plt.figure(figsize=(6,4))\n",
    "# sns.heatmap(conf_matrix_tfidf_svm, annot=True, fmt='d', cmap='OrRd', xticklabels=['Non-Rumor', 'Rumor'], yticklabels=['Non-Rumor', 'Rumor'])\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.title('Confusion Matrix - Support Vector Machine with TF-IDF')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f385e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Support Vector Machine model\n",
    "svm_model_tf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(svm_model_tf, X_train_tfidf, y_train, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "# Train the model on the full training data\n",
    "svm_model_tf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tfidf_svm = svm_model_tf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy_tfidf_svm = accuracy_score(y_test, y_pred_tfidf_svm)\n",
    "precision_tfidf_svm = precision_score(y_test, y_pred_tfidf_svm)\n",
    "recall_tfidf_svm = recall_score(y_test, y_pred_tfidf_svm)\n",
    "f1_tfidf_svm = f1_score(y_test, y_pred_tfidf_svm)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Support Vector Machine with TfidfVectorizer:\")\n",
    "print(f\"Accuracy: {accuracy_tfidf_svm:.4f}\")\n",
    "print(f\"Precision: {precision_tfidf_svm:.4f}\")\n",
    "print(f\"Recall: {recall_tfidf_svm:.4f}\")\n",
    "print(f\"F1 Score: {f1_tfidf_svm:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_tfidf_svm))\n",
    "\n",
    "# Plot confusion matrix\n",
    "conf_matrix_tfidf_svm = confusion_matrix(y_test, y_pred_tfidf_svm)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix_tfidf_svm, annot=True, fmt='d', cmap='OrRd', xticklabels=['Non-Rumor', 'Rumor'], yticklabels=['Non-Rumor', 'Rumor'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Support Vector Machine with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44374386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = conf_matrix_sum.astype(int)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Reliable', 'Unreliable'], yticklabels=['Reliable', 'Unreliable'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Support Vector Machine with TF-IDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be35c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "\n",
    "joblib.dump(svm_model_tf, 'svm_model_tfidf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
